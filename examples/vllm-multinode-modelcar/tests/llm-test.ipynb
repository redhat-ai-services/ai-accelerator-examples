{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c004acc-13cd-4917-8480-592c7c2d623b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Change that following variable settings match your deployed model's *Inference endpoint*. for example: \n",
    "\n",
    "```\n",
    "vllm_endpoint = \"https://model-vllm.apps.clusterx.sandboxx.opentlc.com\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de65d02-84a6-4cff-882e-551cdd42b486",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vllm_endpoint = \"https://multinode-vllm-vllm-multinode.apps.cluster-rdl66.rdl66.sandbox743.opentlc.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f9ece-e9cf-44e2-a8a2-73160186aee8",
   "metadata": {},
   "source": [
    "## Chat completion with Requests library\n",
    "\n",
    "Build and submit the REST request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9386f-683a-4880-b780-c40bec3ab9f8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_model(endpoint):\n",
    "    models_endpoint = f\"{endpoint}/v1/models\"\n",
    "    response = requests.get(models_endpoint)\n",
    "    model = response.json()[\"data\"][0][\"id\"]\n",
    "    return model\n",
    "\n",
    "def completion_request(prompt, model, endpoint):\n",
    "    completion_endpoint = f\"{endpoint}/v1/completions\"\n",
    "    json_data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": [\n",
    "            prompt\n",
    "        ],\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1,\n",
    "        \"n\": 1,\n",
    "        \"stream\": False,\n",
    "        \"logprobs\": 0,\n",
    "        \"echo\": False,\n",
    "        \"stop\": [\n",
    "            \"string\"\n",
    "        ],\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"best_of\": 1,\n",
    "        \"user\": \"string\",\n",
    "        \"top_k\": -1,\n",
    "        \"ignore_eos\": False,\n",
    "        \"use_beam_search\": False,\n",
    "        \"stop_token_ids\": [\n",
    "            0\n",
    "        ],\n",
    "        \"skip_special_tokens\": True,\n",
    "        \"spaces_between_special_tokens\": True,\n",
    "        \"repetition_penalty\": 1,\n",
    "        \"min_p\": 0,\n",
    "        \"include_stop_str_in_output\": False,\n",
    "        \"length_penalty\": 1\n",
    "    }\n",
    "\n",
    "    # If using RHOAI 2.13 or new, set `verify=True`\n",
    "    # Older versions utilize a self-signed cert that is not trusted by default\n",
    "    response = requests.post(completion_endpoint, json=json_data, verify=True)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00de400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(vllm_endpoint)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad16ac-23da-48bd-9796-f8e4cacae981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = completion_request(\"What is AI?\", model, vllm_endpoint)\n",
    "print(prediction[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2dc6ab",
   "metadata": {},
   "source": [
    "## Chat completion with OpenAI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d1dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=f\"{vllm_endpoint}/v1\", api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3dc797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_openai(client):\n",
    "    return client.models.list().data[0].id\n",
    "\n",
    "def completion_openai(prompt, model, client: OpenAI):\n",
    "    chat = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=100,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    "    return chat.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89658f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_openai(client)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is AI?\"\n",
    "response = completion_openai(prompt, model, client)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
